---
layout: default
title: Principles of analytics
nav_order: 2
has_children: true
permalink: docs/principles
---

# Principles of analytics

## How to use this guide

The goal of this guide is to introduce some basic principles to make the use of analytics at DIL more transparent and reproducible. “Analytics” is a general term that encapsulates processing and managing data, coding, and statistical or mathematical modeling. The principles described here apply whenever these three elements are present, no matter what software you are using. They are applications of DIL’s principles of Responsibility, Reproducibility, Credibility, Scalability, Continuity, Flexibility, and Clarity into analytical work.

This guide should be read by all new lab members (especially Research Assistants and Research Professionals). More importantly, though, it should serve as a standing reference that can be consulted by anyone at the Lab. So we recommend that you start by adding it to your bookmarks bar and come back to it whenever you need it. The focus of this guide is on compiling and motivating overarching principles. It will not get into details, but will instead prioritize linking to existing resources. Click through the links to see examples, applications, and more in-depth discussions.

## Motivation

There is one basic idea behind all the principles in this guide: that anyone at any point should be able to understand, use, and scrutinize all the analytics developed at DIL. This means that for all code that is written to analyze data, it should be easy for anyone to (1) understand what the code is doing (2) run the code, and (3) obtain exactly the same results. More often than not, this person will be a future version of the original code writer.

Although economists and other social scientists will generally agree that this is a desirable goal, in practice few of us know how to get there. And there is a good reason for it: we may spend a good chunk of our time as a profession doing analytics, but we don’t really get trained on how to do it. As a result, two unfortunate ideas are imprinted on our hive mind. The first one is that analytics is just a hurdle we need to get through to answer a research question. The second is that we don’t have enough time to learn and implement best practices. These beliefs, however, are far from being true. First of all, good analytics are just as important for credible research as interesting questions and sound methods. Using bad data or using data badly means giving bad answers. Plus, spending some time learning how to best implement your analysis is a guaranteed investment. It will spare you from trying to reinvent the wheel and from falling into well-known traps.

However, that is not to say that as a lab member involved in analytics you have to enjoy writing code or getting your hands dirty with data. A good workflow allows researchers to collaborate with others in ways that play to their strengths and weaknesses. Additionally, no matter what stage of your career you are in, chances are you will continue working with data for a long time. Therefore in building your own workflows you should be realistic about your weak as well as strong sides, so that you can continue enjoying the work that you do. However, to do good research it is essential for every researcher to be able to differentiate between good and bad analytics. So start this process by thinking about how to create an analytic workflow that works for you. In the long haul, this will ensure you have more time and peace of mind to focus on the most important and productive aspects of your research.

